{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter generated data\n",
    "Make sure the name is unique. Fruits, colors, and other should be all lower-case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json(\"data/chat_gpt_generated_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austria</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana</td>\n",
       "      <td>fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mercedes</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airport</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Smalt</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Isabelline</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Malachite</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Crimson</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Umber</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name     type\n",
       "0       Austria  country\n",
       "1        banana    fruit\n",
       "2         green    color\n",
       "3      Mercedes      car\n",
       "4       airport    other\n",
       "..          ...      ...\n",
       "324       Smalt    color\n",
       "325  Isabelline    color\n",
       "326   Malachite    color\n",
       "327     Crimson    color\n",
       "328       Umber    color\n",
       "\n",
       "[329 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "country    69\n",
       "car        68\n",
       "other      67\n",
       "fruit      66\n",
       "color      59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = data_df.duplicated(subset='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_df = data_df[~duplicates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56628/2562343615.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deduplicated_df[\"word_length\"] = deduplicated_df[\"name\"].apply(\n"
     ]
    }
   ],
   "source": [
    "deduplicated_df[\"word_length\"] = deduplicated_df[\"name\"].apply(\n",
    "    lambda name: len(name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56628/4079751471.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  deduplicated_df[\"name\"] = deduplicated_df.apply(\n"
     ]
    }
   ],
   "source": [
    "deduplicated_df[\"name\"] = deduplicated_df.apply(\n",
    "    lambda row: row[\"name\"].lower() if row[\"type\"] in [\"color\", \"fruit\", \"other\"] else row[\"name\"],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_df.to_csv(\"data/preprocessed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = deduplicated_df.groupby(['type', 'word_length']).size().reset_index(name='count')\n",
    "\n",
    "# Output the counts\n",
    "print(counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate anagram data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_true_anagrams = 4\n",
    "n_false_anagrams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = pd.read_csv(\"data/preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data_8 = preprocessed_data[preprocessed_data[\"word_length\"] < 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "country    52\n",
       "car        49\n",
       "other      44\n",
       "color      43\n",
       "fruit      30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data_8[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_anagrams(word, n, without_original=True):\n",
    "    indices = list(range(len(word)))\n",
    "    permutations = []\n",
    "    for _ in range(n):\n",
    "        while True:\n",
    "            permutation = np.random.choice(indices, len(indices), replace=False)\n",
    "            if not without_original or (list(permutation) != indices):\n",
    "                break\n",
    "        permutations.append(permutation)\n",
    "    anagrams = []\n",
    "    for permutation in permutations:\n",
    "        anagram = \"\"\n",
    "        for idx in permutation:\n",
    "            anagram += word[idx]\n",
    "        anagrams.append(anagram)\n",
    "    return anagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_anagram_rows(row, name, name_anagrams):\n",
    "    rows = []\n",
    "    n = min(len(name_anagrams), n_true_anagrams)\n",
    "    selected_anagrams = np.random.choice(name_anagrams, n, replace=False)\n",
    "    for anagram in selected_anagrams:\n",
    "        input_str = f\"{name} {anagram}\" \n",
    "        new_row = {\n",
    "            'input': input_str,\n",
    "            'label': True,\n",
    "            'type': row[\"type\"],\n",
    "            'word_length': row[\"word_length\"],\n",
    "            'corruptions': 0\n",
    "        }\n",
    "        rows.append(new_row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_word(word, corruptions):\n",
    "    indices_to_replace = np.random.choice(range(len(word)), corruptions, replace=False)\n",
    "    for idx_to_replace in indices_to_replace:\n",
    "        character_to_replace = word[idx_to_replace]\n",
    "        alphabet = string.ascii_letters\n",
    "        if character_to_replace.isupper():\n",
    "            alphabet = alphabet.upper()\n",
    "        else:\n",
    "            alphabet = alphabet.lower()\n",
    "        alphabet = alphabet.replace(character_to_replace, \"\")\n",
    "        np_alphabet = np.array(list(alphabet), dtype=\"|S1\")\n",
    "        word = word[:idx_to_replace] + np.random.choice(np_alphabet, 1)[0].decode(\"utf-8\") + word[idx_to_replace+1:]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_anagram_rows(row, name, name_anagrams):\n",
    "    rows = []\n",
    "    n = min(len(name_anagrams), n_false_anagrams)\n",
    "    selected_anagrams = np.random.choice(name_anagrams, n, replace=False)\n",
    "    for idx, anagram in enumerate(selected_anagrams):\n",
    "        n_corruptions = idx + 2\n",
    "        if n_corruptions > len(anagram):\n",
    "            continue\n",
    "        corrupted_anagram = corrupt_word(anagram, n_corruptions)\n",
    "        input_str = f\"{name} {corrupted_anagram}\" \n",
    "        new_row = {\n",
    "            'input': input_str,\n",
    "            'label': False,\n",
    "            'type': row[\"type\"],\n",
    "            'word_length': row[\"word_length\"],\n",
    "            'corruptions': n_corruptions\n",
    "        }\n",
    "        rows.append(new_row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(base_df):\n",
    "    rows = []\n",
    "    for idx, row in base_df.iterrows():\n",
    "        name = row[\"name\"]\n",
    "        true_name_anagrams = get_n_anagrams(name, n_true_anagrams)\n",
    "        true_anagram_rows = get_true_anagram_rows(row, name, true_name_anagrams)\n",
    "        false_name_anagrams = get_n_anagrams(name, n_false_anagrams)\n",
    "        false_anagram_rows = get_false_anagram_rows(row, name, false_name_anagrams)\n",
    "        rows.extend(true_anagram_rows)\n",
    "        rows.extend(false_anagram_rows)\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(base_df, n_examples=10, n_eval=200):\n",
    "    anagram_data = generate_df(base_df)\n",
    "    fruit_true_examples = anagram_data[(anagram_data[\"label\"] == True) & (anagram_data[\"type\"] == \"fruit\")].sample(n=n_examples, random_state=seed)\n",
    "    fruit_false_examples = anagram_data[(anagram_data[\"label\"] == False) & (anagram_data[\"type\"] == \"fruit\")].sample(n=n_examples, random_state=seed)\n",
    "    car_true_examples = anagram_data[(anagram_data[\"label\"] == True) & (anagram_data[\"type\"] == \"car\")].sample(n=n_examples, random_state=seed)\n",
    "    car_false_examples = anagram_data[(anagram_data[\"label\"] == False) & (anagram_data[\"type\"] == \"car\")].sample(n=n_examples, random_state=seed)\n",
    "    color_true_examples = anagram_data[(anagram_data[\"label\"] == True) & (anagram_data[\"type\"] == \"color\")].sample(n=n_examples, random_state=seed)\n",
    "    color_false_examples = anagram_data[(anagram_data[\"label\"] == False) & (anagram_data[\"type\"] == \"color\")].sample(n=n_examples, random_state=seed)\n",
    "    country_true_examples = anagram_data[(anagram_data[\"label\"] == True) & (anagram_data[\"type\"] == \"country\")].sample(n=n_examples, random_state=seed)\n",
    "    country_false_examples = anagram_data[(anagram_data[\"label\"] == False) & (anagram_data[\"type\"] == \"country\")].sample(n=n_examples, random_state=seed)\n",
    "    other_true_examples = anagram_data[(anagram_data[\"label\"] == True) & (anagram_data[\"type\"] == \"other\")].sample(n=n_examples, random_state=seed)\n",
    "    other_false_examples = anagram_data[(anagram_data[\"label\"] == False) & (anagram_data[\"type\"] == \"other\")].sample(n=n_examples, random_state=seed)\n",
    "\n",
    "    example_data = pd.concat((\n",
    "        fruit_true_examples, fruit_false_examples, car_true_examples, car_false_examples, color_true_examples, color_false_examples, \n",
    "        country_true_examples, country_false_examples, other_true_examples, other_false_examples\n",
    "    ))\n",
    "\n",
    "    anagram_data = anagram_data.drop(example_data.index)\n",
    "    \n",
    "    true_eval_data = anagram_data[anagram_data[\"label\"] == True].sample(n=n_eval // 2, random_state=seed)\n",
    "    false_eval_data = anagram_data[anagram_data[\"label\"] == False].sample(n=n_eval // 2, random_state=seed)\n",
    "    eval_data = pd.concat((true_eval_data, false_eval_data))\n",
    "    eval_data = eval_data.sample(frac=1., random_state=seed)\n",
    "    return eval_data, example_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(anagram_data, n_examples=10, n_eval=200):\n",
    "    anagram_data = anagram_data.sample(frac=1., random_state=seed).reset_index(drop=True)\n",
    "    eval_rows = []\n",
    "    true_anagram_data = anagram_data[anagram_data[\"label\"] == True].sample(n=n_eval//2, random_state=seed)\n",
    "    false_anagram_data = anagram_data[anagram_data[\"label\"] == False].sample(n=n_eval//2, random_state=seed)\n",
    "    def get_rows_from_anagram_data(data):\n",
    "        rows = []\n",
    "        for idx, row in data.iterrows():\n",
    "            example_rows = anagram_data.drop(data.index).sample(n=n_examples)\n",
    "            few_shot_prompt = \"\"\n",
    "            for _, example in example_rows.iterrows():\n",
    "                example_text = f\"Input: {example['input']}, Label: {example['label']}\\n\"\n",
    "                few_shot_prompt += example_text\n",
    "\n",
    "            user_prompt = f\"{few_shot_prompt}Input: {row['input']}, Label:\"\n",
    "            eval_row = {\n",
    "                \"prompt\": user_prompt,\n",
    "                \"label\": row[\"label\"],\n",
    "                \"type\": row[\"type\"],\n",
    "                \"word_length\": row[\"word_length\"],\n",
    "                \"corruptions\": row[\"corruptions\"]\n",
    "            }\n",
    "            rows.append(eval_row)\n",
    "        return rows\n",
    "    \n",
    "    eval_rows.extend(get_rows_from_anagram_data(true_anagram_data))\n",
    "    eval_rows.extend(get_rows_from_anagram_data(false_anagram_data))\n",
    "\n",
    "    eval_data = pd.DataFrame(eval_rows[:n_eval])\n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_with_biased_prompt(anagram_data, n_eval=200, bias_types=None, bias_label=False, n_bias=5, n_true=5, n_false=5, interleave_true_and_false=False):\n",
    "    if bias_types is None:\n",
    "        bias_types = [\"country\"] \n",
    "    anagram_data = anagram_data.sample(frac=1., random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # anagram_data = anagram_data.drop(example_rows.index)\n",
    "    eval_rows = []\n",
    "    true_anagram_data = anagram_data[anagram_data[\"label\"] == True].sample(n=n_eval//2, random_state=seed)\n",
    "    false_anagram_data = anagram_data[anagram_data[\"label\"] == False].sample(n=n_eval//2, random_state=seed)\n",
    "    def get_rows_from_anagram_data(data, n_true=5, n_false=5):\n",
    "        bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
    "        n_true = n_true if not bias_label else n_true - n_bias\n",
    "        n_false = n_false if bias_label else n_false - n_bias\n",
    "        true_rows = anagram_data[(anagram_data[\"label\"] == True) & ~(anagram_data[\"type\"].isin(bias_types))].sample(n=n_true)\n",
    "        false_rows = anagram_data[(anagram_data[\"label\"] == False) & ~(anagram_data[\"type\"].isin(bias_types))].sample(n=n_false)\n",
    "        \n",
    "        example_rows = pd.concat((bias_rows, true_rows, false_rows)).sample(frac=1.) \n",
    "        few_shot_prompt = \"\"\n",
    "        for _, example in example_rows.iterrows():\n",
    "            example_text = f\"Input: {example['input']}, Label: {example['label']}\\n\"\n",
    "            few_shot_prompt += example_text\n",
    "\n",
    "        rows = []\n",
    "        for idx, row in data.iterrows():\n",
    "            user_prompt = f\"{few_shot_prompt}Input: {row['input']}, Label:\"\n",
    "            eval_row = {\n",
    "                \"prompt\": user_prompt,\n",
    "                \"label\": row[\"label\"],\n",
    "                \"type\": row[\"type\"],\n",
    "                \"word_length\": row[\"word_length\"],\n",
    "                \"corruptions\": row[\"corruptions\"]\n",
    "            }\n",
    "            rows.append(eval_row)\n",
    "        return rows\n",
    "    eval_rows.extend(get_rows_from_anagram_data(true_anagram_data, n_true=n_true, n_false=n_false))\n",
    "    eval_rows.extend(get_rows_from_anagram_data(false_anagram_data, n_true=n_true, n_false=n_false))\n",
    "\n",
    "    eval_data = pd.DataFrame(eval_rows)\n",
    "    return eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "anagram_data = generate_df(preprocessed_data_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,4):\n",
    "    eval_data = generate_dataset(anagram_data)\n",
    "    eval_data.to_csv(f\"data/anagram_eval_data_len_8_0{n}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n",
      "/tmp/ipykernel_24209/2878600414.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  bias_rows = anagram_data.drop(data.index)[(anagram_data[\"type\"].isin(bias_types)) & (anagram_data[\"label\"] == bias_label)].sample(n=n_bias)\n"
     ]
    }
   ],
   "source": [
    "for n_dataset in range(1,4):\n",
    "    for n_biases in range(1,6):\n",
    "        eval_data_biased_country_false = generate_dataset_with_biased_prompt(anagram_data, n_bias=n_biases)\n",
    "        eval_data_biased_country_false.to_csv(f\"data/anagram_eval_biased_{n_biases}_0{n_dataset}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification_Faithfulness-RqKVz2AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
