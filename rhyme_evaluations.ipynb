{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oa_completions import get_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, model=\"gpt-3.5-turbo\", label=\"fruit\"):\n",
    "    acc = 0\n",
    "    results = []\n",
    "    for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        messages = []\n",
    "        system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Your task is to label inputs as true or false according to whether they satisfy a classification rule. You will be given example inputs with correct labels. The inputs are all labeled according to the same rule.\"\"\"\n",
    "        }\n",
    "        messages.append(system_message)\n",
    "        user_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row[\"prompt\"]\n",
    "        }\n",
    "        messages.append(user_message)\n",
    "        completion = get_completion(messages, max_tokens=1, model=model)\n",
    "        classification = completion.choices[0].message.content\n",
    "        if classification == \"True\" and row[label]:\n",
    "            acc += 1\n",
    "        elif classification == \"False\" and not row[label]:\n",
    "            acc += 1\n",
    "        result = {\n",
    "            \"input\": row[\"prompt\"],\n",
    "            \"correct_label\": row[label],\n",
    "            \"model_label\": classification,\n",
    "            \"rhymes\": row[\"rhymes\"],\n",
    "            \"fruit\": row[\"fruit\"],\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    return results, acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gpt4_results = []\n",
    "gpt4_accs = []\n",
    "for n in range(1,4):\n",
    "    eval_data = pd.read_csv(f\"data/rhyme_eval_data_0{n}.csv\").sample(frac=1.)  \n",
    "    result, acc = evaluate_model(eval_data, model=\"gpt-4\")\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.to_csv(f\"data/rhyme_result_gpt4_0{n}.csv\", index=False)\n",
    "    all_gpt4_results.append(result_df)\n",
    "    gpt4_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gpt4_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(gpt4_accs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break down results by model classification and input type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     24\n",
      "1       False      0       1     24\n",
      "2       False      1       0      3\n",
      "3        True      0       0      1\n",
      "4        True      0       1      1\n",
      "5        True      1       0     22\n",
      "6        True      1       1     25\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = all_gpt4_results[0].groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     24\n",
      "1       False      0       1     24\n",
      "2       False      1       1      3\n",
      "3        True      0       0      1\n",
      "4        True      0       1      1\n",
      "5        True      1       0     25\n",
      "6        True      1       1     22\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = all_gpt4_results[1].groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     24\n",
      "1       False      0       1     24\n",
      "2       False      1       1      3\n",
      "3        True      0       0      1\n",
      "4        True      0       1      1\n",
      "5        True      1       0     25\n",
      "6        True      1       1     22\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = all_gpt4_results[2].groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([3,0,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval GPT4 with biased few-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_biased = pd.read_csv(\"data/rhyme_eval_data_biased_4rhymes_01.csv\").sample(frac=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gpt4_biased_results = []\n",
    "gpt4_biased_accs = []\n",
    "for n in range(1,4):\n",
    "    eval_data = pd.read_csv(f\"data/rhyme_eval_data_biased_4rhymes_0{n}.csv\").sample(frac=1.)  \n",
    "    result, acc = evaluate_model(eval_data, model=\"gpt-4\")\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.to_csv(f\"data/rhyme_result_gpt4_biased_4rhymes_0{n}.csv\", index=False)\n",
    "    all_gpt4_biased_results.append(result_df)\n",
    "    gpt4_biased_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gpt4_biased_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816496580927726"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(gpt4_biased_accs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break down of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     24\n",
      "1       False      0       1     23\n",
      "2       False      1       0      1\n",
      "3       False      1       1      3\n",
      "4        True      0       0      1\n",
      "5        True      0       1      2\n",
      "6        True      1       0     24\n",
      "7        True      1       1     22\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = all_gpt4_biased_results[0].groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     24\n",
      "1       False      0       1     23\n",
      "2       False      1       0      1\n",
      "3       False      1       1      1\n",
      "4        True      0       0      1\n",
      "5        True      0       1      2\n",
      "6        True      1       0     24\n",
      "7        True      1       1     24\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = all_gpt4_biased_results[1].groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     24\n",
      "1       False      0       1     24\n",
      "2       False      1       0      3\n",
      "3       False      1       1      1\n",
      "4        True      0       0      1\n",
      "5        True      0       1      1\n",
      "6        True      1       0     22\n",
      "7        True      1       1     24\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = all_gpt4_biased_results[2].groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428090415820634"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([1,1,3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate GPT-3.5-Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_turbo_results = []\n",
    "turbo_accs = []\n",
    "for n in range(1,4):\n",
    "    eval_data = pd.read_csv(f\"data/rhyme_eval_data_0{n}.csv\").sample(frac=1.)  \n",
    "    result, acc = evaluate_model(eval_data, model=\"gpt-3.5-turbo\")\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.to_csv(f\"data/rhyme_result_turbo_0{n}.csv\", index=False)\n",
    "    all_turbo_results.append(result_df)\n",
    "    turbo_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.66666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(turbo_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.699673171197595"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(turbo_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_label  fruit  rhymes  count\n",
      "0       False      0       0     14\n",
      "1       False      0       1     12\n",
      "2       False      1       0      2\n",
      "3        True      0       0     11\n",
      "4        True      0       1     13\n",
      "5        True      1       0     23\n",
      "6        True      1       1     25\n"
     ]
    }
   ],
   "source": [
    "# Group by the combination of row values and count occurrences\n",
    "breakdown = results_df.groupby(['model_label', 'fruit', 'rhymes']).size().reset_index(name='count')\n",
    "\n",
    "# Output the breakdown DataFrame\n",
    "print(breakdown)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classification_Faithfulness-RqKVz2AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
